{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbf3de71",
   "metadata": {},
   "source": [
    "## CNN from scratch\n",
    "\n",
    "The aim of this project is to build a Convolutional Neural Network entirely from scratch using Pandas (For data manipulation) and Numpy (For mathematical operations)\n",
    "\n",
    "The training data used in this project is the MNIST dataset containing handwritten digits from 0 to 9.\n",
    "\n",
    "After training and testing the model on the MNIST dataset, I will test the model on my own handwritten digits.\n",
    "\n",
    "To process the custom images and feed them into the model, I will use OpenCV. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162a49df",
   "metadata": {},
   "source": [
    "### Conceptual Overview\n",
    "\n",
    "The Neural Network will have a very simple two-layer architecture.\n",
    "\n",
    "Consider A^[0] as the input layer. This layer will have 784 nodes/units, corresponding to the 784 pixels in each 28x28 image.\n",
    "\n",
    "Consider A^[1] as the hidden layer. This layer will have 10 nodes/units with ReLU activation function.\n",
    "\n",
    "Consider A^[2] as the output layer. This layer will have 10 nodes/units corresponding to the 10 digit classes we are trying to predict. This layer has a softmax activation function.\n",
    "\n",
    "Mathematically speaking this is what happens under the hood:\n",
    "\n",
    "**Forward propagation**\n",
    "\n",
    "$$Z^{[1]} = W^{[1]} X + b^{[1]}$$\n",
    "$$A^{[1]} = g_{\\text{ReLU}}(Z^{[1]}))$$\n",
    "$$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$$\n",
    "$$A^{[2]} = g_{\\text{softmax}}(Z^{[2]})$$\n",
    "\n",
    "**Backward propagation**\n",
    "\n",
    "$$dZ^{[2]} = A^{[2]} - Y$$\n",
    "$$dW^{[2]} = \\frac{1}{m} dZ^{[2]} A^{[1]T}$$\n",
    "$$dB^{[2]} = \\frac{1}{m} \\Sigma {dZ^{[2]}}$$\n",
    "$$dZ^{[1]} = W^{[2]T} dZ^{[2]} .* g^{[1]\\prime} (z^{[1]})$$\n",
    "$$dW^{[1]} = \\frac{1}{m} dZ^{[1]} A^{[0]T}$$\n",
    "$$dB^{[1]} = \\frac{1}{m} \\Sigma {dZ^{[1]}}$$\n",
    "\n",
    "**Parameter updates**\n",
    "\n",
    "$$W^{[2]} := W^{[2]} - \\alpha dW^{[2]}$$\n",
    "$$b^{[2]} := b^{[2]} - \\alpha db^{[2]}$$\n",
    "$$W^{[1]} := W^{[1]} - \\alpha dW^{[1]}$$\n",
    "$$b^{[1]} := b^{[1]} - \\alpha db^{[1]}$$\n",
    "\n",
    "The goal is to get the optimal parameters for our model to start making better predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9fde8a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-13T04:28:57.546079Z",
     "iopub.status.busy": "2025-09-13T04:28:57.545733Z",
     "iopub.status.idle": "2025-09-13T04:29:02.546213Z",
     "shell.execute_reply": "2025-09-13T04:29:02.544931Z"
    },
    "papermill": {
     "duration": 5.00666,
     "end_time": "2025-09-13T04:29:02.548128",
     "exception": false,
     "start_time": "2025-09-13T04:28:57.541468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data_train = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1d50adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T04:29:02.555297Z",
     "iopub.status.busy": "2025-09-13T04:29:02.554949Z",
     "iopub.status.idle": "2025-09-13T04:29:02.588221Z",
     "shell.execute_reply": "2025-09-13T04:29:02.587246Z"
    },
    "papermill": {
     "duration": 0.038538,
     "end_time": "2025-09-13T04:29:02.589941",
     "exception": false,
     "start_time": "2025-09-13T04:29:02.551403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e6ca26",
   "metadata": {},
   "source": [
    "### Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c1bfa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T04:29:02.596982Z",
     "iopub.status.busy": "2025-09-13T04:29:02.596602Z",
     "iopub.status.idle": "2025-09-13T04:29:02.604294Z",
     "shell.execute_reply": "2025-09-13T04:29:02.603272Z"
    },
    "papermill": {
     "duration": 0.013108,
     "end_time": "2025-09-13T04:29:02.606001",
     "exception": false,
     "start_time": "2025-09-13T04:29:02.592893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    \"\"\"Utility class for data preprocessing.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_data(data_train,test_size = 1000):\n",
    "        \"\"\"\n",
    "        Prepare and split data into train and validation sets.\n",
    "        \n",
    "        Args:\n",
    "            data: Raw data array\n",
    "            test_size: Number of samples for test set\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (X_train, Y_train, X_val, Y_val)\n",
    "        \"\"\"\n",
    "        # Convert to numpy array\n",
    "        data = np.array(data_train)\n",
    "        m, n = data.shape\n",
    "        \n",
    "        # Shuffle data\n",
    "        np.random.shuffle(data)\n",
    "        \n",
    "        # Split into validation and train\n",
    "        data_val = data[:test_size].T\n",
    "        Y_val = data_val[0].astype(int)\n",
    "        X_val = data_val[1:n].astype(float)\n",
    "        \n",
    "        data_train_split = data[test_size:m].T\n",
    "        Y_train = data_train_split[0].astype(int)\n",
    "        X_train = data_train_split[1:n].astype(float)\n",
    "        \n",
    "        # Normalize pixel values\n",
    "        X_train = X_train / 255.0\n",
    "        X_val = X_val / 255.0\n",
    "        \n",
    "        # Invert the pixel values\n",
    "        X_train = 1.0 - X_train\n",
    "        X_val = 1.0 - X_val\n",
    "\n",
    "        return X_train, Y_train, X_val, Y_val\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_test_data(data_test):\n",
    "        \"\"\"\n",
    "        Process test data (no labels).\n",
    "        \n",
    "        Args:\n",
    "            data_test: Test data DataFrame (no labels, only pixels)\n",
    "            \n",
    "        Returns:\n",
    "            np.array: X_test - processed test data\n",
    "        \"\"\"\n",
    "        # Convert to numpy array\n",
    "        test_array = np.array(data_test)\n",
    "        X_test = test_array.T.astype(float)  # All columns are pixels\n",
    "        \n",
    "        # Apply same preprocessing as training data\n",
    "        X_test = X_test / 255.0\n",
    "        X_test = 1.0 - X_test  # Same inversion\n",
    "        \n",
    "        return X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1758f117",
   "metadata": {},
   "source": [
    "### Build the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c72b4c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T04:29:02.614028Z",
     "iopub.status.busy": "2025-09-13T04:29:02.613633Z",
     "iopub.status.idle": "2025-09-13T04:29:02.635061Z",
     "shell.execute_reply": "2025-09-13T04:29:02.633954Z"
    },
    "papermill": {
     "duration": 0.027938,
     "end_time": "2025-09-13T04:29:02.636845",
     "exception": false,
     "start_time": "2025-09-13T04:29:02.608907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    \"\"\"\n",
    "    A simple 2-layer neural network for digit classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=784, hidden_size=10, output_size=10):\n",
    "        \"\"\"\n",
    "        Initialize the neural network with specified layer sizes.\n",
    "        \n",
    "        Args:\n",
    "            input_size (int): Number of input features (default: 784 for 28x28 images)\n",
    "            hidden_size (int): Number of hidden layer neurons\n",
    "            output_size (int): Number of output classes\n",
    "        \"\"\"\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.W1, self.b1, self.W2, self.b2 = self._init_params()\n",
    "        \n",
    "    def _init_params(self):\n",
    "        \"\"\"Initialize weights and biases with random values.\"\"\"\n",
    "        W1 = np.random.rand(self.hidden_size, self.input_size) - 0.5\n",
    "        b1 = np.random.rand(self.hidden_size, 1) - 0.5\n",
    "        W2 = np.random.rand(self.output_size, self.hidden_size) - 0.5\n",
    "        b2 = np.random.rand(self.output_size, 1) - 0.5\n",
    "        return W1, b1, W2, b2\n",
    "    \n",
    "    @staticmethod\n",
    "    def relu(Z):\n",
    "        \"\"\"ReLU activation function.\"\"\"\n",
    "        return np.maximum(Z, 0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def relu_derivative(Z):\n",
    "        \"\"\"Derivative of ReLU activation function.\"\"\"\n",
    "        return Z > 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(Z):\n",
    "        \"\"\"Softmax activation function.\"\"\"\n",
    "        # Subtract max for numerical stability\n",
    "        Z_stable = Z - np.max(Z, axis=0, keepdims=True)\n",
    "        exp_Z = np.exp(Z_stable)\n",
    "        return exp_Z / np.sum(exp_Z, axis=0, keepdims=True)\n",
    "    \n",
    "    @staticmethod\n",
    "    def one_hot_encode(Y):\n",
    "        \"\"\"Convert labels to one-hot encoding.\"\"\"\n",
    "        one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "        one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "        return one_hot_Y.T\n",
    "    \n",
    "    def forward_propagation(self, X):\n",
    "        \"\"\"\n",
    "        Perform forward propagation through the network.\n",
    "        \n",
    "        Args:\n",
    "            X (np.array): Input data of shape (input_size, m)\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (Z1, A1, Z2, A2) - intermediate values and final output\n",
    "        \"\"\"\n",
    "        Z1 = self.W1.dot(X) + self.b1\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = self.W2.dot(A1) + self.b2\n",
    "        A2 = self.softmax(Z2)\n",
    "        return Z1, A1, Z2, A2\n",
    "    \n",
    "    def backward_propagation(self, Z1, A1, Z2, A2, X, Y):\n",
    "        \"\"\"\n",
    "        Perform backward propagation to compute gradients.\n",
    "        \n",
    "        Args:\n",
    "            Z1, A1, Z2, A2: Forward propagation outputs\n",
    "            X: Input data\n",
    "            Y: True labels\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Gradients (dW1, db1, dW2, db2)\n",
    "        \"\"\"\n",
    "        m = X.shape[1]  # number of examples\n",
    "        one_hot_Y = self.one_hot_encode(Y)\n",
    "        \n",
    "        # Backward propagation\n",
    "        dZ2 = A2 - one_hot_Y\n",
    "        dW2 = (1 / m) * dZ2.dot(A1.T)\n",
    "        db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        \n",
    "        dZ1 = self.W2.T.dot(dZ2) * self.relu_derivative(Z1)\n",
    "        dW1 = (1 / m) * dZ1.dot(X.T)\n",
    "        db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "        \n",
    "        return dW1, db1, dW2, db2\n",
    "    \n",
    "    def update_parameters(self, dW1, db1, dW2, db2, learning_rate):\n",
    "        \"\"\"Update network parameters using gradients.\"\"\"\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.b1 -= learning_rate * db1\n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.b2 -= learning_rate * db2\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions on input data.\"\"\"\n",
    "        _, _, _, A2 = self.forward_propagation(X)\n",
    "        return np.argmax(A2, axis=0)\n",
    "    \n",
    "    def compute_accuracy(self, predictions, Y):\n",
    "        \"\"\"Compute accuracy of predictions.\"\"\"\n",
    "        return np.sum(predictions == Y) / Y.size\n",
    "    \n",
    "    def compute_loss(self, A2, Y):\n",
    "        \"\"\"Compute cross-entropy loss.\"\"\"\n",
    "        m = Y.size\n",
    "        one_hot_Y = self.one_hot_encode(Y)\n",
    "        # Add small epsilon to prevent log(0)\n",
    "        epsilon = 1e-15\n",
    "        A2_clipped = np.clip(A2, epsilon, 1 - epsilon)\n",
    "        loss = -np.sum(one_hot_Y * np.log(A2_clipped)) / m\n",
    "        return loss\n",
    "    \n",
    "    def train(self, X, Y, learning_rate, epochs, print_every=10):\n",
    "        \"\"\"\n",
    "        Train the neural network using gradient descent.\n",
    "        \n",
    "        Args:\n",
    "            X: Training data of shape (input_size, m)\n",
    "            Y: Training labels\n",
    "            learning_rate: Learning rate for gradient descent\n",
    "            epochs: Number of training iterations\n",
    "            print_every: Print progress every n epochs\n",
    "            \n",
    "        Returns:\n",
    "            dict: Training history with losses and accuracies\n",
    "        \"\"\"\n",
    "        history = {'loss': [], 'accuracy': []}\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Forward propagation\n",
    "            Z1, A1, Z2, A2 = self.forward_propagation(X)\n",
    "            \n",
    "            # Backward propagation\n",
    "            dW1, db1, dW2, db2 = self.backward_propagation(Z1, A1, Z2, A2, X, Y)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.update_parameters(dW1, db1, dW2, db2, learning_rate)\n",
    "            \n",
    "            # Compute metrics\n",
    "            if epoch % print_every == 0 or epoch == epochs - 1:\n",
    "                loss = self.compute_loss(A2, Y)\n",
    "                predictions = self.predict(X)\n",
    "                accuracy = self.compute_accuracy(predictions, Y)\n",
    "                \n",
    "                history['loss'].append(loss)\n",
    "                history['accuracy'].append(accuracy)\n",
    "                \n",
    "                \n",
    "                print(f\"Epoch {epoch:4d}: Loss = {loss:.4f}, Accuracy = {accuracy:.4f}\")\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def evaluate(self, X, Y):\n",
    "        \"\"\"Evaluate the model on test data.\"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        accuracy = self.compute_accuracy(predictions, Y)\n",
    "        _, _, _, A2 = self.forward_propagation(X)\n",
    "        loss = self.compute_loss(A2, Y)\n",
    "        return {'accuracy': accuracy, 'loss': loss, 'predictions': predictions}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f879f",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6118311f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T04:29:02.643747Z",
     "iopub.status.busy": "2025-09-13T04:29:02.643378Z",
     "iopub.status.idle": "2025-09-13T04:29:40.371381Z",
     "shell.execute_reply": "2025-09-13T04:29:40.369996Z"
    },
    "papermill": {
     "duration": 37.733545,
     "end_time": "2025-09-13T04:29:40.373129",
     "exception": false,
     "start_time": "2025-09-13T04:29:02.639584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0: Loss = 11.8556, Accuracy = 0.1188\n",
      "Epoch   10: Loss = 2.3376, Accuracy = 0.1169\n",
      "Epoch   20: Loss = 2.3191, Accuracy = 0.1183\n",
      "Epoch   30: Loss = 2.3037, Accuracy = 0.1232\n",
      "Epoch   40: Loss = 2.2863, Accuracy = 0.1406\n",
      "Epoch   50: Loss = 2.2658, Accuracy = 0.1538\n",
      "Epoch   60: Loss = 2.2425, Accuracy = 0.1643\n",
      "Epoch   70: Loss = 2.2178, Accuracy = 0.1720\n",
      "Epoch   80: Loss = 2.1930, Accuracy = 0.1766\n",
      "Epoch   90: Loss = 2.1687, Accuracy = 0.1813\n",
      "Epoch  100: Loss = 2.1453, Accuracy = 0.1860\n",
      "Epoch  110: Loss = 2.1227, Accuracy = 0.1900\n",
      "Epoch  120: Loss = 2.1009, Accuracy = 0.1933\n",
      "Epoch  130: Loss = 2.0797, Accuracy = 0.1967\n",
      "Epoch  140: Loss = 2.0591, Accuracy = 0.2000\n",
      "Epoch  150: Loss = 2.0389, Accuracy = 0.2026\n",
      "Epoch  160: Loss = 2.0192, Accuracy = 0.2056\n",
      "Epoch  170: Loss = 1.9998, Accuracy = 0.2519\n",
      "Epoch  180: Loss = 1.9809, Accuracy = 0.2567\n",
      "Epoch  190: Loss = 1.9626, Accuracy = 0.2598\n",
      "Epoch  200: Loss = 1.9450, Accuracy = 0.2632\n",
      "Epoch  210: Loss = 1.9280, Accuracy = 0.2693\n",
      "Epoch  220: Loss = 1.9117, Accuracy = 0.2752\n",
      "Epoch  230: Loss = 1.8961, Accuracy = 0.2820\n",
      "Epoch  240: Loss = 1.8811, Accuracy = 0.2904\n",
      "Epoch  250: Loss = 1.8667, Accuracy = 0.2978\n",
      "Epoch  260: Loss = 1.8527, Accuracy = 0.3040\n",
      "Epoch  270: Loss = 1.8391, Accuracy = 0.3117\n",
      "Epoch  280: Loss = 1.8257, Accuracy = 0.3191\n",
      "Epoch  290: Loss = 1.8125, Accuracy = 0.3279\n",
      "Epoch  300: Loss = 1.7992, Accuracy = 0.3355\n",
      "Epoch  310: Loss = 1.7856, Accuracy = 0.3428\n",
      "Epoch  320: Loss = 1.7715, Accuracy = 0.3477\n",
      "Epoch  330: Loss = 1.7567, Accuracy = 0.3520\n",
      "Epoch  340: Loss = 1.7409, Accuracy = 0.3819\n",
      "Epoch  350: Loss = 1.7236, Accuracy = 0.3890\n",
      "Epoch  360: Loss = 1.7051, Accuracy = 0.3949\n",
      "Epoch  370: Loss = 1.6858, Accuracy = 0.4006\n",
      "Epoch  380: Loss = 1.6660, Accuracy = 0.4072\n",
      "Epoch  390: Loss = 1.6463, Accuracy = 0.4137\n",
      "Epoch  400: Loss = 1.6271, Accuracy = 0.4179\n",
      "Epoch  410: Loss = 1.6084, Accuracy = 0.4230\n",
      "Epoch  420: Loss = 1.5903, Accuracy = 0.4293\n",
      "Epoch  430: Loss = 1.5730, Accuracy = 0.4341\n",
      "Epoch  440: Loss = 1.5563, Accuracy = 0.4398\n",
      "Epoch  450: Loss = 1.5403, Accuracy = 0.4464\n",
      "Epoch  460: Loss = 1.5250, Accuracy = 0.4528\n",
      "Epoch  470: Loss = 1.5102, Accuracy = 0.4590\n",
      "Epoch  480: Loss = 1.4960, Accuracy = 0.4659\n",
      "Epoch  490: Loss = 1.4824, Accuracy = 0.4726\n",
      "Epoch  500: Loss = 1.4692, Accuracy = 0.4788\n",
      "Epoch  510: Loss = 1.4565, Accuracy = 0.4844\n",
      "Epoch  520: Loss = 1.4443, Accuracy = 0.4896\n",
      "Epoch  530: Loss = 1.4324, Accuracy = 0.4950\n",
      "Epoch  540: Loss = 1.4210, Accuracy = 0.4999\n",
      "Epoch  550: Loss = 1.4100, Accuracy = 0.5044\n",
      "Epoch  560: Loss = 1.3993, Accuracy = 0.5084\n",
      "Epoch  570: Loss = 1.3890, Accuracy = 0.5122\n",
      "Epoch  580: Loss = 1.3789, Accuracy = 0.5151\n",
      "Epoch  590: Loss = 1.3692, Accuracy = 0.5190\n",
      "Epoch  600: Loss = 1.3597, Accuracy = 0.5228\n",
      "Epoch  610: Loss = 1.3505, Accuracy = 0.5260\n",
      "Epoch  620: Loss = 1.3415, Accuracy = 0.5301\n",
      "Epoch  630: Loss = 1.3327, Accuracy = 0.5331\n",
      "Epoch  640: Loss = 1.3241, Accuracy = 0.5359\n",
      "Epoch  650: Loss = 1.3157, Accuracy = 0.5385\n",
      "Epoch  660: Loss = 1.3075, Accuracy = 0.5419\n",
      "Epoch  670: Loss = 1.2994, Accuracy = 0.5450\n",
      "Epoch  680: Loss = 1.2914, Accuracy = 0.5480\n",
      "Epoch  690: Loss = 1.2836, Accuracy = 0.5502\n",
      "Epoch  700: Loss = 1.2758, Accuracy = 0.5533\n",
      "Epoch  710: Loss = 1.2681, Accuracy = 0.5569\n",
      "Epoch  720: Loss = 1.2604, Accuracy = 0.5598\n",
      "Epoch  730: Loss = 1.2528, Accuracy = 0.5628\n",
      "Epoch  740: Loss = 1.2453, Accuracy = 0.5653\n",
      "Epoch  750: Loss = 1.2378, Accuracy = 0.5679\n",
      "Epoch  760: Loss = 1.2303, Accuracy = 0.5697\n",
      "Epoch  770: Loss = 1.2229, Accuracy = 0.5726\n",
      "Epoch  780: Loss = 1.2154, Accuracy = 0.5750\n",
      "Epoch  790: Loss = 1.2079, Accuracy = 0.5784\n",
      "Epoch  800: Loss = 1.2003, Accuracy = 0.5812\n",
      "Epoch  810: Loss = 1.1927, Accuracy = 0.5848\n",
      "Epoch  820: Loss = 1.1851, Accuracy = 0.5877\n",
      "Epoch  830: Loss = 1.1774, Accuracy = 0.5909\n",
      "Epoch  840: Loss = 1.1697, Accuracy = 0.5949\n",
      "Epoch  850: Loss = 1.1619, Accuracy = 0.5984\n",
      "Epoch  860: Loss = 1.1542, Accuracy = 0.6015\n",
      "Epoch  870: Loss = 1.1464, Accuracy = 0.6048\n",
      "Epoch  880: Loss = 1.1387, Accuracy = 0.6075\n",
      "Epoch  890: Loss = 1.1309, Accuracy = 0.6112\n",
      "Epoch  900: Loss = 1.1232, Accuracy = 0.6150\n",
      "Epoch  910: Loss = 1.1155, Accuracy = 0.6178\n",
      "Epoch  920: Loss = 1.1078, Accuracy = 0.6207\n",
      "Epoch  930: Loss = 1.1002, Accuracy = 0.6250\n",
      "Epoch  940: Loss = 1.0927, Accuracy = 0.6288\n",
      "Epoch  950: Loss = 1.0852, Accuracy = 0.6323\n",
      "Epoch  960: Loss = 1.0778, Accuracy = 0.6350\n",
      "Epoch  970: Loss = 1.0705, Accuracy = 0.6375\n",
      "Epoch  980: Loss = 1.0633, Accuracy = 0.6406\n",
      "Epoch  990: Loss = 1.0561, Accuracy = 0.6450\n",
      "Epoch 1000: Loss = 1.0491, Accuracy = 0.6500\n",
      "Epoch 1010: Loss = 1.0421, Accuracy = 0.6533\n",
      "Epoch 1020: Loss = 1.0352, Accuracy = 0.6552\n",
      "Epoch 1030: Loss = 1.0284, Accuracy = 0.6578\n",
      "Epoch 1040: Loss = 1.0217, Accuracy = 0.6603\n",
      "Epoch 1050: Loss = 1.0151, Accuracy = 0.6630\n",
      "Epoch 1060: Loss = 1.0086, Accuracy = 0.6653\n",
      "Epoch 1070: Loss = 1.0022, Accuracy = 0.6671\n",
      "Epoch 1080: Loss = 0.9959, Accuracy = 0.6689\n",
      "Epoch 1090: Loss = 0.9897, Accuracy = 0.6711\n",
      "Epoch 1100: Loss = 0.9836, Accuracy = 0.6732\n",
      "Epoch 1110: Loss = 0.9775, Accuracy = 0.6754\n",
      "Epoch 1120: Loss = 0.9716, Accuracy = 0.6776\n",
      "Epoch 1130: Loss = 0.9658, Accuracy = 0.6800\n",
      "Epoch 1140: Loss = 0.9600, Accuracy = 0.6821\n",
      "Epoch 1150: Loss = 0.9544, Accuracy = 0.6847\n",
      "Epoch 1160: Loss = 0.9489, Accuracy = 0.6865\n",
      "Epoch 1170: Loss = 0.9434, Accuracy = 0.6886\n",
      "Epoch 1180: Loss = 0.9381, Accuracy = 0.6904\n",
      "Epoch 1190: Loss = 0.9329, Accuracy = 0.6930\n",
      "Epoch 1200: Loss = 0.9278, Accuracy = 0.6953\n",
      "Epoch 1210: Loss = 0.9229, Accuracy = 0.6970\n",
      "Epoch 1220: Loss = 0.9181, Accuracy = 0.6985\n",
      "Epoch 1230: Loss = 0.9135, Accuracy = 0.7006\n",
      "Epoch 1240: Loss = 0.9098, Accuracy = 0.7026\n",
      "Epoch 1250: Loss = 0.9081, Accuracy = 0.7032\n",
      "Epoch 1260: Loss = 0.9125, Accuracy = 0.7009\n",
      "Epoch 1270: Loss = 0.9246, Accuracy = 0.6972\n",
      "Epoch 1280: Loss = 0.9298, Accuracy = 0.6972\n",
      "Epoch 1290: Loss = 0.9173, Accuracy = 0.7016\n",
      "Epoch 1300: Loss = 0.9033, Accuracy = 0.7067\n",
      "Epoch 1310: Loss = 0.8940, Accuracy = 0.7105\n",
      "Epoch 1320: Loss = 0.8873, Accuracy = 0.7130\n",
      "Epoch 1330: Loss = 0.8821, Accuracy = 0.7150\n",
      "Epoch 1340: Loss = 0.8782, Accuracy = 0.7167\n",
      "Epoch 1350: Loss = 0.8744, Accuracy = 0.7184\n",
      "Epoch 1360: Loss = 0.8709, Accuracy = 0.7201\n",
      "Epoch 1370: Loss = 0.8677, Accuracy = 0.7218\n",
      "Epoch 1380: Loss = 0.8642, Accuracy = 0.7236\n",
      "Epoch 1390: Loss = 0.8603, Accuracy = 0.7254\n",
      "Epoch 1400: Loss = 0.8562, Accuracy = 0.7269\n",
      "Epoch 1410: Loss = 0.8525, Accuracy = 0.7281\n",
      "Epoch 1420: Loss = 0.8486, Accuracy = 0.7293\n",
      "Epoch 1430: Loss = 0.8449, Accuracy = 0.7313\n",
      "Epoch 1440: Loss = 0.8416, Accuracy = 0.7325\n",
      "Epoch 1450: Loss = 0.8383, Accuracy = 0.7340\n",
      "Epoch 1460: Loss = 0.8352, Accuracy = 0.7350\n",
      "Epoch 1470: Loss = 0.8322, Accuracy = 0.7362\n",
      "Epoch 1480: Loss = 0.8296, Accuracy = 0.7372\n",
      "Epoch 1490: Loss = 0.8273, Accuracy = 0.7385\n",
      "Epoch 1499: Loss = 0.8247, Accuracy = 0.7339\n"
     ]
    }
   ],
   "source": [
    "preprocessor = DataPreprocessor()\n",
    "X_train, Y_train, X_val, Y_val= preprocessor.prepare_data(data_train)\n",
    "    \n",
    "# Create and train model\n",
    "model = CNN(input_size=784, hidden_size=10, output_size=10)\n",
    "history = model.train(X_train, Y_train, learning_rate=0.04, epochs=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339e255",
   "metadata": {},
   "source": [
    "### Testing on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53ed4cf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T04:29:40.386527Z",
     "iopub.status.busy": "2025-09-13T04:29:40.385549Z",
     "iopub.status.idle": "2025-09-13T04:29:40.395583Z",
     "shell.execute_reply": "2025-09-13T04:29:40.394577Z"
    },
    "papermill": {
     "duration": 0.018118,
     "end_time": "2025-09-13T04:29:40.397344",
     "exception": false,
     "start_time": "2025-09-13T04:29:40.379226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7140\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_results = model.evaluate(X_val, Y_val)\n",
    "print(f\"Validation Accuracy: {test_results['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c87993a",
   "metadata": {},
   "source": [
    "### Testing on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21414101",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= preprocessor.prepare_test_data(data_test)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95d798bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 4 7 2 7 0 3 0 3]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[:10])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "rlearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 49.297898,
   "end_time": "2025-09-13T04:29:40.923894",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-13T04:28:51.625996",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
