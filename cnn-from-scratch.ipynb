{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbf3de71",
   "metadata": {},
   "source": [
    "## CNN from scratch\n",
    "\n",
    "The aim of this project is to build a Convolutional Neural Network entirely from scratch using Pandas (For data manipulation) and Numpy (For mathematical operations)\n",
    "\n",
    "The training data used in this project is the MNIST dataset containing handwritten digits from 0 to 9.\n",
    "\n",
    "After training and testing the model on the MNIST dataset, I will test the model on my own handwritten digits.\n",
    "\n",
    "To process the custom images and feed them into the model, I will use OpenCV. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162a49df",
   "metadata": {},
   "source": [
    "### Conceptual Overview\n",
    "\n",
    "The Neural Network will have a very simple two-layer architecture.\n",
    "\n",
    "Consider A^[0] as the input layer. This layer will have 784 nodes/units, corresponding to the 784 pixels in each 28x28 image.\n",
    "\n",
    "Consider A^[1] as the hidden layer. This layer will have 10 nodes/units with ReLU activation function.\n",
    "\n",
    "Consider A^[2] as the output layer. This layer will have 10 nodes/units corresponding to the 10 digit classes we are trying to predict. This layer has a softmax activation function.\n",
    "\n",
    "Mathematically speaking this is what happens under the hood:\n",
    "\n",
    "**Forward propagation**\n",
    "\n",
    "$$Z^{[1]} = W^{[1]} X + b^{[1]}$$\n",
    "$$A^{[1]} = g_{\\text{ReLU}}(Z^{[1]}))$$\n",
    "$$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$$\n",
    "$$A^{[2]} = g_{\\text{softmax}}(Z^{[2]})$$\n",
    "\n",
    "**Backward propagation**\n",
    "\n",
    "$$dZ^{[2]} = A^{[2]} - Y$$\n",
    "$$dW^{[2]} = \\frac{1}{m} dZ^{[2]} A^{[1]T}$$\n",
    "$$dB^{[2]} = \\frac{1}{m} \\Sigma {dZ^{[2]}}$$\n",
    "$$dZ^{[1]} = W^{[2]T} dZ^{[2]} .* g^{[1]\\prime} (z^{[1]})$$\n",
    "$$dW^{[1]} = \\frac{1}{m} dZ^{[1]} A^{[0]T}$$\n",
    "$$dB^{[1]} = \\frac{1}{m} \\Sigma {dZ^{[1]}}$$\n",
    "\n",
    "**Parameter updates**\n",
    "\n",
    "$$W^{[2]} := W^{[2]} - \\alpha dW^{[2]}$$\n",
    "$$b^{[2]} := b^{[2]} - \\alpha db^{[2]}$$\n",
    "$$W^{[1]} := W^{[1]} - \\alpha dW^{[1]}$$\n",
    "$$b^{[1]} := b^{[1]} - \\alpha db^{[1]}$$\n",
    "\n",
    "The goal is to get the optimal parameters for our model to start making better predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9fde8a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-13T04:28:57.546079Z",
     "iopub.status.busy": "2025-09-13T04:28:57.545733Z",
     "iopub.status.idle": "2025-09-13T04:29:02.546213Z",
     "shell.execute_reply": "2025-09-13T04:29:02.544931Z"
    },
    "papermill": {
     "duration": 5.00666,
     "end_time": "2025-09-13T04:29:02.548128",
     "exception": false,
     "start_time": "2025-09-13T04:28:57.541468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1d50adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T04:29:02.555297Z",
     "iopub.status.busy": "2025-09-13T04:29:02.554949Z",
     "iopub.status.idle": "2025-09-13T04:29:02.588221Z",
     "shell.execute_reply": "2025-09-13T04:29:02.587246Z"
    },
    "papermill": {
     "duration": 0.038538,
     "end_time": "2025-09-13T04:29:02.589941",
     "exception": false,
     "start_time": "2025-09-13T04:29:02.551403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e6ca26",
   "metadata": {},
   "source": [
    "### Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1bfa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T04:29:02.596982Z",
     "iopub.status.busy": "2025-09-13T04:29:02.596602Z",
     "iopub.status.idle": "2025-09-13T04:29:02.604294Z",
     "shell.execute_reply": "2025-09-13T04:29:02.603272Z"
    },
    "papermill": {
     "duration": 0.013108,
     "end_time": "2025-09-13T04:29:02.606001",
     "exception": false,
     "start_time": "2025-09-13T04:29:02.592893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    \"\"\"Utility class for data preprocessing.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_data(data, test_size=1000):\n",
    "        \"\"\"\n",
    "        Prepare and split data into train and test sets.\n",
    "        \n",
    "        Args:\n",
    "            data: Raw data array\n",
    "            test_size: Number of samples for test set\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (X_train, Y_train, X_test, Y_test)\n",
    "        \"\"\"\n",
    "        data = np.array(data)\n",
    "        m, n = data.shape\n",
    "        \n",
    "        # Shuffle data\n",
    "        np.random.shuffle(data)\n",
    "        \n",
    "        # Split into test and train\n",
    "        data_test = data[:test_size].T\n",
    "        Y_test = data_test[0].astype(int)\n",
    "        X_test = data_test[1:n].astype(float)\n",
    "        \n",
    "        data_train = data[test_size:m].T\n",
    "        Y_train = data_train[0].astype(int)\n",
    "        X_train = data_train[1:n].astype(float)\n",
    "        \n",
    "        # Normalize pixel values\n",
    "        X_train = X_train / 255.0\n",
    "        X_test = X_test / 255.0\n",
    "        \n",
    "        # Invert the pixel values\n",
    "        X_train = 1.0 - X_train\n",
    "        X_test = 1.0 - X_test\n",
    "\n",
    "        return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1758f117",
   "metadata": {},
   "source": [
    "### Build the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c72b4c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T04:29:02.614028Z",
     "iopub.status.busy": "2025-09-13T04:29:02.613633Z",
     "iopub.status.idle": "2025-09-13T04:29:02.635061Z",
     "shell.execute_reply": "2025-09-13T04:29:02.633954Z"
    },
    "papermill": {
     "duration": 0.027938,
     "end_time": "2025-09-13T04:29:02.636845",
     "exception": false,
     "start_time": "2025-09-13T04:29:02.608907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    \"\"\"\n",
    "    A simple 2-layer neural network for digit classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=784, hidden_size=10, output_size=10):\n",
    "        \"\"\"\n",
    "        Initialize the neural network with specified layer sizes.\n",
    "        \n",
    "        Args:\n",
    "            input_size (int): Number of input features (default: 784 for 28x28 images)\n",
    "            hidden_size (int): Number of hidden layer neurons\n",
    "            output_size (int): Number of output classes\n",
    "        \"\"\"\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.W1, self.b1, self.W2, self.b2 = self._init_params()\n",
    "        \n",
    "    def _init_params(self):\n",
    "        \"\"\"Initialize weights and biases with random values.\"\"\"\n",
    "        W1 = np.random.rand(self.hidden_size, self.input_size) - 0.5\n",
    "        b1 = np.random.rand(self.hidden_size, 1) - 0.5\n",
    "        W2 = np.random.rand(self.output_size, self.hidden_size) - 0.5\n",
    "        b2 = np.random.rand(self.output_size, 1) - 0.5\n",
    "        return W1, b1, W2, b2\n",
    "    \n",
    "    @staticmethod\n",
    "    def relu(Z):\n",
    "        \"\"\"ReLU activation function.\"\"\"\n",
    "        return np.maximum(Z, 0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def relu_derivative(Z):\n",
    "        \"\"\"Derivative of ReLU activation function.\"\"\"\n",
    "        return Z > 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(Z):\n",
    "        \"\"\"Softmax activation function.\"\"\"\n",
    "        # Subtract max for numerical stability\n",
    "        Z_stable = Z - np.max(Z, axis=0, keepdims=True)\n",
    "        exp_Z = np.exp(Z_stable)\n",
    "        return exp_Z / np.sum(exp_Z, axis=0, keepdims=True)\n",
    "    \n",
    "    @staticmethod\n",
    "    def one_hot_encode(Y):\n",
    "        \"\"\"Convert labels to one-hot encoding.\"\"\"\n",
    "        one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "        one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "        return one_hot_Y.T\n",
    "    \n",
    "    def forward_propagation(self, X):\n",
    "        \"\"\"\n",
    "        Perform forward propagation through the network.\n",
    "        \n",
    "        Args:\n",
    "            X (np.array): Input data of shape (input_size, m)\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (Z1, A1, Z2, A2) - intermediate values and final output\n",
    "        \"\"\"\n",
    "        Z1 = self.W1.dot(X) + self.b1\n",
    "        A1 = self.relu(Z1)\n",
    "        Z2 = self.W2.dot(A1) + self.b2\n",
    "        A2 = self.softmax(Z2)\n",
    "        return Z1, A1, Z2, A2\n",
    "    \n",
    "    def backward_propagation(self, Z1, A1, Z2, A2, X, Y):\n",
    "        \"\"\"\n",
    "        Perform backward propagation to compute gradients.\n",
    "        \n",
    "        Args:\n",
    "            Z1, A1, Z2, A2: Forward propagation outputs\n",
    "            X: Input data\n",
    "            Y: True labels\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Gradients (dW1, db1, dW2, db2)\n",
    "        \"\"\"\n",
    "        m = X.shape[1]  # number of examples\n",
    "        one_hot_Y = self.one_hot_encode(Y)\n",
    "        \n",
    "        # Backward propagation\n",
    "        dZ2 = A2 - one_hot_Y\n",
    "        dW2 = (1 / m) * dZ2.dot(A1.T)\n",
    "        db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        \n",
    "        dZ1 = self.W2.T.dot(dZ2) * self.relu_derivative(Z1)\n",
    "        dW1 = (1 / m) * dZ1.dot(X.T)\n",
    "        db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "        \n",
    "        return dW1, db1, dW2, db2\n",
    "    \n",
    "    def update_parameters(self, dW1, db1, dW2, db2, learning_rate):\n",
    "        \"\"\"Update network parameters using gradients.\"\"\"\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.b1 -= learning_rate * db1\n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.b2 -= learning_rate * db2\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions on input data.\"\"\"\n",
    "        _, _, _, A2 = self.forward_propagation(X)\n",
    "        return np.argmax(A2, axis=0)\n",
    "    \n",
    "    def compute_accuracy(self, predictions, Y):\n",
    "        \"\"\"Compute accuracy of predictions.\"\"\"\n",
    "        return np.sum(predictions == Y) / Y.size\n",
    "    \n",
    "    def compute_loss(self, A2, Y):\n",
    "        \"\"\"Compute cross-entropy loss.\"\"\"\n",
    "        m = Y.size\n",
    "        one_hot_Y = self.one_hot_encode(Y)\n",
    "        # Add small epsilon to prevent log(0)\n",
    "        epsilon = 1e-15\n",
    "        A2_clipped = np.clip(A2, epsilon, 1 - epsilon)\n",
    "        loss = -np.sum(one_hot_Y * np.log(A2_clipped)) / m\n",
    "        return loss\n",
    "    \n",
    "    def train(self, X, Y, learning_rate, epochs, print_every=10):\n",
    "        \"\"\"\n",
    "        Train the neural network using gradient descent.\n",
    "        \n",
    "        Args:\n",
    "            X: Training data of shape (input_size, m)\n",
    "            Y: Training labels\n",
    "            learning_rate: Learning rate for gradient descent\n",
    "            epochs: Number of training iterations\n",
    "            print_every: Print progress every n epochs\n",
    "            \n",
    "        Returns:\n",
    "            dict: Training history with losses and accuracies\n",
    "        \"\"\"\n",
    "        history = {'loss': [], 'accuracy': []}\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Forward propagation\n",
    "            Z1, A1, Z2, A2 = self.forward_propagation(X)\n",
    "            \n",
    "            # Backward propagation\n",
    "            dW1, db1, dW2, db2 = self.backward_propagation(Z1, A1, Z2, A2, X, Y)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.update_parameters(dW1, db1, dW2, db2, learning_rate)\n",
    "            \n",
    "            # Compute metrics\n",
    "            if epoch % print_every == 0 or epoch == epochs - 1:\n",
    "                loss = self.compute_loss(A2, Y)\n",
    "                predictions = self.predict(X)\n",
    "                accuracy = self.compute_accuracy(predictions, Y)\n",
    "                \n",
    "                history['loss'].append(loss)\n",
    "                history['accuracy'].append(accuracy)\n",
    "                \n",
    "                \n",
    "                print(f\"Epoch {epoch:4d}: Loss = {loss:.4f}, Accuracy = {accuracy:.4f}\")\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def evaluate(self, X, Y):\n",
    "        \"\"\"Evaluate the model on test data.\"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        accuracy = self.compute_accuracy(predictions, Y)\n",
    "        _, _, _, A2 = self.forward_propagation(X)\n",
    "        loss = self.compute_loss(A2, Y)\n",
    "        return {'accuracy': accuracy, 'loss': loss, 'predictions': predictions}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f879f",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118311f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T04:29:02.643747Z",
     "iopub.status.busy": "2025-09-13T04:29:02.643378Z",
     "iopub.status.idle": "2025-09-13T04:29:40.371381Z",
     "shell.execute_reply": "2025-09-13T04:29:40.369996Z"
    },
    "papermill": {
     "duration": 37.733545,
     "end_time": "2025-09-13T04:29:40.373129",
     "exception": false,
     "start_time": "2025-09-13T04:29:02.639584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0: Loss = 3.8290, Accuracy = 0.1412\n",
      "Epoch   10: Loss = 2.0560, Accuracy = 0.2800\n",
      "Epoch   20: Loss = 1.8058, Accuracy = 0.3897\n",
      "Epoch   30: Loss = 1.6128, Accuracy = 0.4695\n",
      "Epoch   40: Loss = 1.4512, Accuracy = 0.5370\n",
      "Epoch   50: Loss = 1.3164, Accuracy = 0.5873\n",
      "Epoch   60: Loss = 1.2054, Accuracy = 0.6247\n",
      "Epoch   70: Loss = 1.1148, Accuracy = 0.6532\n",
      "Epoch   80: Loss = 1.0408, Accuracy = 0.6767\n",
      "Epoch   90: Loss = 0.9798, Accuracy = 0.6949\n",
      "Epoch  100: Loss = 0.9289, Accuracy = 0.7100\n",
      "Epoch  110: Loss = 0.8859, Accuracy = 0.7233\n",
      "Epoch  120: Loss = 0.8493, Accuracy = 0.7348\n",
      "Epoch  130: Loss = 0.8177, Accuracy = 0.7450\n",
      "Epoch  140: Loss = 0.7899, Accuracy = 0.7539\n",
      "Epoch  150: Loss = 0.7655, Accuracy = 0.7616\n",
      "Epoch  160: Loss = 0.7437, Accuracy = 0.7681\n",
      "Epoch  170: Loss = 0.7243, Accuracy = 0.7739\n",
      "Epoch  180: Loss = 0.7068, Accuracy = 0.7800\n",
      "Epoch  190: Loss = 0.6909, Accuracy = 0.7848\n",
      "Epoch  200: Loss = 0.6764, Accuracy = 0.7899\n",
      "Epoch  210: Loss = 0.6632, Accuracy = 0.7945\n",
      "Epoch  220: Loss = 0.6511, Accuracy = 0.7985\n",
      "Epoch  230: Loss = 0.6399, Accuracy = 0.8021\n",
      "Epoch  240: Loss = 0.6296, Accuracy = 0.8048\n",
      "Epoch  250: Loss = 0.6201, Accuracy = 0.8077\n",
      "Epoch  260: Loss = 0.6112, Accuracy = 0.8106\n",
      "Epoch  270: Loss = 0.6029, Accuracy = 0.8133\n",
      "Epoch  280: Loss = 0.5951, Accuracy = 0.8154\n",
      "Epoch  290: Loss = 0.5878, Accuracy = 0.8186\n",
      "Epoch  300: Loss = 0.5810, Accuracy = 0.8209\n",
      "Epoch  310: Loss = 0.5745, Accuracy = 0.8231\n",
      "Epoch  320: Loss = 0.5685, Accuracy = 0.8254\n",
      "Epoch  330: Loss = 0.5627, Accuracy = 0.8272\n",
      "Epoch  340: Loss = 0.5572, Accuracy = 0.8293\n",
      "Epoch  350: Loss = 0.5520, Accuracy = 0.8306\n",
      "Epoch  360: Loss = 0.5471, Accuracy = 0.8320\n",
      "Epoch  370: Loss = 0.5423, Accuracy = 0.8336\n",
      "Epoch  380: Loss = 0.5378, Accuracy = 0.8352\n",
      "Epoch  390: Loss = 0.5335, Accuracy = 0.8373\n",
      "Epoch  400: Loss = 0.5294, Accuracy = 0.8385\n",
      "Epoch  410: Loss = 0.5254, Accuracy = 0.8400\n",
      "Epoch  420: Loss = 0.5216, Accuracy = 0.8414\n",
      "Epoch  430: Loss = 0.5179, Accuracy = 0.8426\n",
      "Epoch  440: Loss = 0.5144, Accuracy = 0.8442\n",
      "Epoch  450: Loss = 0.5110, Accuracy = 0.8453\n",
      "Epoch  460: Loss = 0.5077, Accuracy = 0.8462\n",
      "Epoch  470: Loss = 0.5045, Accuracy = 0.8474\n",
      "Epoch  480: Loss = 0.5014, Accuracy = 0.8486\n",
      "Epoch  490: Loss = 0.4985, Accuracy = 0.8494\n",
      "Epoch  499: Loss = 0.4959, Accuracy = 0.8503\n"
     ]
    }
   ],
   "source": [
    "preprocessor = DataPreprocessor()\n",
    "X_train, Y_train, X_test, Y_test = preprocessor.prepare_data(data)\n",
    "    \n",
    "# Create and train model\n",
    "model = CNN(input_size=784, hidden_size=10, output_size=10)\n",
    "history = model.train(X_train, Y_train, learning_rate=0.05, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339e255",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53ed4cf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T04:29:40.386527Z",
     "iopub.status.busy": "2025-09-13T04:29:40.385549Z",
     "iopub.status.idle": "2025-09-13T04:29:40.395583Z",
     "shell.execute_reply": "2025-09-13T04:29:40.394577Z"
    },
    "papermill": {
     "duration": 0.018118,
     "end_time": "2025-09-13T04:29:40.397344",
     "exception": false,
     "start_time": "2025-09-13T04:29:40.379226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8340\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_results = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test Accuracy: {test_results['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84987d9",
   "metadata": {},
   "source": [
    "### Processing custom Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042a8b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_image(webcam_id=0):\n",
    "\n",
    "    # Initialize the webcam\n",
    "    print(\"Initialising video capture\")\n",
    "    cap = cv2.VideoCapture(webcam_id)\n",
    "    time.sleep(1.000)\n",
    "    # Check if the webcam is opened correctly\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        exit()\n",
    "\n",
    "    # Capture a single frame\n",
    "    print(\"Capturing frame\")\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame was captured correctly\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame.\")\n",
    "        exit()\n",
    "  \n",
    "    # Release the webcam\n",
    "    print(\"Releasing webcam\")\n",
    "    cap.release()\n",
    "\n",
    "    # Convert from BGR to RGB\n",
    "    return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 49.297898,
   "end_time": "2025-09-13T04:29:40.923894",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-13T04:28:51.625996",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
